"""
å‘é‡æ•°æ®åº“è¯Šæ–­å·¥å…· - æ·±åº¦æ’æŸ¥æ–‡æ¡£æ£€ç´¢é—®é¢˜

ä½¿ç”¨æ–¹æ³•:
    python diagnose_vector_db.py <username> [conversation_id]

ç¤ºä¾‹:
    python diagnose_vector_db.py tomyb
    python diagnose_vector_db.py tomyb 123
"""
import sqlite3
import sys
import os
from pathlib import Path
from datetime import datetime
import json

class VectorDBDiagnostics:
    def __init__(self, username):
        self.username = username
        self.vector_db_path = f"custom_rag_{username}.db"
        self.users_db_path = "users.db"
        self.issues_found = []
        self.warnings = []

    def check_db_exists(self):
        """æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        print("\n" + "="*60)
        print("ğŸ“ æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶")
        print("="*60)

        if not os.path.exists(self.vector_db_path):
            self.issues_found.append(f"âŒ å‘é‡æ•°æ®åº“ä¸å­˜åœ¨: {self.vector_db_path}")
            print(f"âŒ å‘é‡æ•°æ®åº“ä¸å­˜åœ¨: {self.vector_db_path}")
            return False
        else:
            size = os.path.getsize(self.vector_db_path) / 1024 / 1024
            print(f"âœ… å‘é‡æ•°æ®åº“å­˜åœ¨: {self.vector_db_path} ({size:.2f} MB)")

        if not os.path.exists(self.users_db_path):
            self.issues_found.append(f"âŒ ç”¨æˆ·æ•°æ®åº“ä¸å­˜åœ¨: {self.users_db_path}")
            print(f"âŒ ç”¨æˆ·æ•°æ®åº“ä¸å­˜åœ¨: {self.users_db_path}")
            return False
        else:
            size = os.path.getsize(self.users_db_path) / 1024 / 1024
            print(f"âœ… ç”¨æˆ·æ•°æ®åº“å­˜åœ¨: {self.users_db_path} ({size:.2f} MB)")

        return True

    def check_schema(self):
        """æ£€æŸ¥æ•°æ®åº“è¡¨ç»“æ„"""
        print("\n" + "="*60)
        print("ğŸ—ï¸  æ£€æŸ¥æ•°æ®åº“è¡¨ç»“æ„")
        print("="*60)

        # æ£€æŸ¥å‘é‡æ•°æ®åº“
        conn = sqlite3.connect(self.vector_db_path)
        cursor = conn.cursor()

        # æ£€æŸ¥ chunks è¡¨æ˜¯å¦æœ‰ conversation_id
        cursor.execute("PRAGMA table_info(chunks)")
        columns = {row[1]: row[2] for row in cursor.fetchall()}

        print(f"\nğŸ“‹ chunks è¡¨å­—æ®µ:")
        for col, dtype in columns.items():
            print(f"   - {col}: {dtype}")

        if 'conversation_id' not in columns:
            self.issues_found.append("âŒ chunks è¡¨ç¼ºå°‘ conversation_id å­—æ®µ!")
            print("\nâŒ ç¼ºå°‘ conversation_id å­—æ®µ - éœ€è¦è¿è¡Œè¿ç§»è„šæœ¬!")
        else:
            print("\nâœ… conversation_id å­—æ®µå­˜åœ¨")

        conn.close()

        # æ£€æŸ¥ç”¨æˆ·æ•°æ®åº“
        conn = sqlite3.connect(self.users_db_path)
        cursor = conn.cursor()

        cursor.execute("PRAGMA table_info(user_documents)")
        columns = {row[1]: row[2] for row in cursor.fetchall()}

        print(f"\nğŸ“‹ user_documents è¡¨å­—æ®µ:")
        for col, dtype in columns.items():
            print(f"   - {col}: {dtype}")

        if 'conversation_id' not in columns:
            self.issues_found.append("âŒ user_documents è¡¨ç¼ºå°‘ conversation_id å­—æ®µ!")
            print("\nâŒ ç¼ºå°‘ conversation_id å­—æ®µ - éœ€è¦è¿è¡Œè¿ç§»è„šæœ¬!")
        else:
            print("\nâœ… conversation_id å­—æ®µå­˜åœ¨")

        conn.close()

    def analyze_chunks_distribution(self):
        """åˆ†æ chunks çš„åˆ†å¸ƒæƒ…å†µ"""
        print("\n" + "="*60)
        print("ğŸ“Š åˆ†ææ–‡æ¡£å— (chunks) åˆ†å¸ƒ")
        print("="*60)

        conn = sqlite3.connect(self.vector_db_path)
        cursor = conn.cursor()

        # æ€»å—æ•°
        cursor.execute("SELECT COUNT(*) FROM chunks")
        total_chunks = cursor.fetchone()[0]
        print(f"\næ€»å—æ•°: {total_chunks}")

        if total_chunks == 0:
            self.warnings.append("âš ï¸  å‘é‡æ•°æ®åº“ä¸­æ²¡æœ‰ä»»ä½•æ–‡æ¡£å—!")
            print("âš ï¸  å‘é‡æ•°æ®åº“ä¸ºç©º!")
            conn.close()
            return

        # æŒ‰ conversation_id åˆ†ç»„ç»Ÿè®¡
        cursor.execute("""
            SELECT
                conversation_id,
                COUNT(*) as chunk_count,
                MIN(chunk_index) as min_index,
                MAX(chunk_index) as max_index
            FROM chunks
            GROUP BY conversation_id
            ORDER BY conversation_id
        """)

        print("\næŒ‰å¯¹è¯IDåˆ†ç»„:")
        print(f"{'å¯¹è¯ID':<15} {'å—æ•°é‡':<10} {'ç´¢å¼•èŒƒå›´':<15}")
        print("-" * 45)

        null_conversation_chunks = 0
        for row in cursor.fetchall():
            conv_id = row[0] if row[0] is not None else "NULL (æ—§æ•°æ®)"
            chunk_count = row[1]
            index_range = f"{row[2]}-{row[3]}"
            print(f"{str(conv_id):<15} {chunk_count:<10} {index_range:<15}")

            if row[0] is None:
                null_conversation_chunks = chunk_count

        if null_conversation_chunks > 0:
            self.warnings.append(
                f"âš ï¸  å‘ç° {null_conversation_chunks} ä¸ªæœªç»‘å®šå¯¹è¯çš„æ—§å— (conversation_id IS NULL)"
            )
            print(f"\nâš ï¸  å‘ç° {null_conversation_chunks} ä¸ªæ—§å—æœªç»‘å®šåˆ°ä»»ä½•å¯¹è¯")
            print("   è¿™äº›å—ä¼šåœ¨æ‰€æœ‰æœç´¢ä¸­å‡ºç°,å¯èƒ½å¯¼è‡´æ±¡æŸ“!")

        conn.close()

    def analyze_documents(self):
        """åˆ†ææ–‡æ¡£è®°å½•"""
        print("\n" + "="*60)
        print("ğŸ“„ åˆ†æç”¨æˆ·æ–‡æ¡£è®°å½•")
        print("="*60)

        conn = sqlite3.connect(self.users_db_path)
        cursor = conn.cursor()

        # è·å–ç”¨æˆ·ID
        cursor.execute("SELECT id FROM users WHERE username = ?", (self.username,))
        user_row = cursor.fetchone()
        if not user_row:
            print(f"âŒ ç”¨æˆ·ä¸å­˜åœ¨: {self.username}")
            conn.close()
            return

        user_id = user_row[0]
        print(f"ç”¨æˆ·ID: {user_id}")

        # æ–‡æ¡£ç»Ÿè®¡
        cursor.execute("""
            SELECT
                id, filename, conversation_id,
                datetime(uploaded_at, 'localtime') as upload_time
            FROM user_documents
            WHERE user_id = ?
            ORDER BY uploaded_at DESC
        """, (user_id,))

        docs = cursor.fetchall()

        if not docs:
            print("\nâš ï¸  è¯¥ç”¨æˆ·æ²¡æœ‰ä¸Šä¼ ä»»ä½•æ–‡æ¡£!")
            conn.close()
            return

        print(f"\næ–‡æ¡£æ€»æ•°: {len(docs)}")
        print("\næœ€è¿‘ä¸Šä¼ çš„æ–‡æ¡£:")
        print(f"{'æ–‡æ¡£ID':<10} {'æ–‡ä»¶å':<30} {'å¯¹è¯ID':<15} {'ä¸Šä¼ æ—¶é—´':<20}")
        print("-" * 80)

        null_conversation_docs = 0
        for doc in docs[:10]:  # åªæ˜¾ç¤ºæœ€è¿‘10ä¸ª
            conv_id = doc[2] if doc[2] is not None else "NULL (æœªç»‘å®š)"
            print(f"{doc[0]:<10} {doc[1]:<30} {str(conv_id):<15} {doc[3]:<20}")

            if doc[2] is None:
                null_conversation_docs += 1

        if null_conversation_docs > 0:
            self.warnings.append(
                f"âš ï¸  å‘ç° {null_conversation_docs} ä¸ªæ–‡æ¡£æœªç»‘å®šåˆ°å¯¹è¯"
            )

        conn.close()

    def test_search_query(self, conversation_id=None):
        """æ¨¡æ‹Ÿæœç´¢æŸ¥è¯¢,æ£€æŸ¥SQLæ‰§è¡Œ"""
        print("\n" + "="*60)
        print("ğŸ” æ¨¡æ‹Ÿæœç´¢æŸ¥è¯¢")
        print("="*60)

        conn = sqlite3.connect(self.vector_db_path)
        cursor = conn.cursor()

        if conversation_id:
            print(f"\næœç´¢èŒƒå›´: å¯¹è¯ #{conversation_id}")
            cursor.execute("""
                SELECT COUNT(*)
                FROM chunks
                WHERE conversation_id = ? OR conversation_id IS NULL
            """, (conversation_id,))
        else:
            print(f"\næœç´¢èŒƒå›´: æ‰€æœ‰æ–‡æ¡£ (æ— ä¼šè¯è¿‡æ»¤)")
            cursor.execute("SELECT COUNT(*) FROM chunks")

        count = cursor.fetchone()[0]
        print(f"å¯æœç´¢çš„å—æ•°é‡: {count}")

        if count == 0:
            self.issues_found.append(
                f"âŒ å¯¹è¯ {conversation_id} æ²¡æœ‰ä»»ä½•å¯æœç´¢çš„æ–‡æ¡£å—!"
            )
            print(f"âŒ è¯¥å¯¹è¯æ²¡æœ‰æ–‡æ¡£!")

        # æ£€æŸ¥æ˜¯å¦æœ‰ NULL conversation_id çš„å—
        cursor.execute("SELECT COUNT(*) FROM chunks WHERE conversation_id IS NULL")
        null_count = cursor.fetchone()[0]

        if null_count > 0:
            print(f"\nâš ï¸  è­¦å‘Š: å‘ç° {null_count} ä¸ªæœªç»‘å®šå¯¹è¯çš„å—")
            print(f"   è¿™äº›å—ä¼šåœ¨æ‰€æœ‰æœç´¢ä¸­å‡ºç°,å¯èƒ½æ˜¯æ—§æ•°æ®æ±¡æŸ“æº!")

            # æ˜¾ç¤ºæœªç»‘å®šå—çš„æ¥æºæ–‡æ¡£
            cursor.execute("""
                SELECT DISTINCT d.filename
                FROM chunks c
                JOIN documents d ON c.document_id = d.id
                WHERE c.conversation_id IS NULL
                LIMIT 5
            """)

            print("\n   æœªç»‘å®šå—çš„æ¥æºæ–‡æ¡£:")
            for row in cursor.fetchall():
                print(f"   - {row[0]}")

        conn.close()

    def check_embedding_cache(self):
        """æ£€æŸ¥åµŒå…¥ç¼“å­˜çŠ¶æ€"""
        print("\n" + "="*60)
        print("ğŸ’¾ æ£€æŸ¥åµŒå…¥ç¼“å­˜")
        print("="*60)

        # æ£€æŸ¥æ˜¯å¦æœ‰åµŒå…¥ç¼“å­˜æ–‡ä»¶
        cache_patterns = [
            "embedding_cache.pkl",
            f"embedding_cache_{self.username}.pkl",
            ".embedding_cache"
        ]

        found_cache = False
        for pattern in cache_patterns:
            if os.path.exists(pattern):
                size = os.path.getsize(pattern) / 1024
                print(f"âš ï¸  å‘ç°ç¼“å­˜æ–‡ä»¶: {pattern} ({size:.2f} KB)")
                print(f"   ç¼“å­˜å¯èƒ½å¯¼è‡´ä½¿ç”¨æ—§çš„åµŒå…¥å‘é‡!")
                found_cache = True

        if not found_cache:
            print("âœ… æœªå‘ç°åµŒå…¥ç¼“å­˜æ–‡ä»¶")

    def suggest_fixes(self):
        """å»ºè®®ä¿®å¤æ–¹æ¡ˆ"""
        print("\n" + "="*60)
        print("ğŸ› ï¸  ä¿®å¤å»ºè®®")
        print("="*60)

        if not self.issues_found and not self.warnings:
            print("\nâœ… æ²¡æœ‰å‘ç°ä¸¥é‡é—®é¢˜!")
            return

        if self.issues_found:
            print("\nâŒ ä¸¥é‡é—®é¢˜:")
            for i, issue in enumerate(self.issues_found, 1):
                print(f"   {i}. {issue}")

        if self.warnings:
            print("\nâš ï¸  è­¦å‘Š:")
            for i, warning in enumerate(self.warnings, 1):
                print(f"   {i}. {warning}")

        print("\n" + "="*60)
        print("ğŸ’¡ å»ºè®®çš„ä¿®å¤æ­¥éª¤:")
        print("="*60)

        # æ ¹æ®é—®é¢˜æä¾›é’ˆå¯¹æ€§å»ºè®®
        if any("ç¼ºå°‘ conversation_id" in issue for issue in self.issues_found):
            print("\n1ï¸âƒ£  è¿è¡Œæ•°æ®åº“è¿ç§»:")
            print("   python migrate_session_isolation.py")

        if any("æœªç»‘å®šå¯¹è¯" in warning for warning in self.warnings):
            print("\n2ï¸âƒ£  æ¸…ç†æœªç»‘å®šçš„æ—§æ•°æ®:")
            print("   python cleanup_orphan_chunks.py")

        if any("å‘é‡æ•°æ®åº“ä¸ºç©º" in warning for warning in self.warnings):
            print("\n3ï¸âƒ£  é‡æ–°ä¸Šä¼ æ–‡æ¡£:")
            print("   - åˆ›å»ºæ–°å¯¹è¯")
            print("   - ä¸Šä¼  PDF æ–‡æ¡£")
            print("   - éªŒè¯æ–‡æ¡£æ˜¯å¦æ­£ç¡®å¤„ç†")

        print("\n4ï¸âƒ£  éªŒè¯ä¿®å¤:")
        print("   python test_session_isolation.py")

    def run_full_diagnosis(self, conversation_id=None):
        """è¿è¡Œå®Œæ•´è¯Šæ–­"""
        print("\n" + "ğŸ”¬"*30)
        print("å‘é‡æ•°æ®åº“æ·±åº¦è¯Šæ–­å·¥å…·")
        print("ğŸ”¬"*30)
        print(f"\nç”¨æˆ·: {self.username}")
        if conversation_id:
            print(f"å¯¹è¯ID: {conversation_id}")
        print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        if not self.check_db_exists():
            print("\nâŒ æ•°æ®åº“æ–‡ä»¶ç¼ºå¤±,æ— æ³•ç»§ç»­è¯Šæ–­")
            return

        self.check_schema()
        self.analyze_chunks_distribution()
        self.analyze_documents()
        self.test_search_query(conversation_id)
        self.check_embedding_cache()
        self.suggest_fixes()

        # ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
        report = {
            "timestamp": datetime.now().isoformat(),
            "username": self.username,
            "conversation_id": conversation_id,
            "issues": self.issues_found,
            "warnings": self.warnings
        }

        report_file = f"diagnosis_report_{self.username}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print("\n" + "="*60)
        print(f"ğŸ“‹ è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        print("="*60)


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python diagnose_vector_db.py <username> [conversation_id]")
        print("ç¤ºä¾‹: python diagnose_vector_db.py tomyb")
        print("ç¤ºä¾‹: python diagnose_vector_db.py tomyb 123")
        sys.exit(1)

    username = sys.argv[1]
    conversation_id = int(sys.argv[2]) if len(sys.argv) > 2 else None

    diagnostics = VectorDBDiagnostics(username)
    diagnostics.run_full_diagnosis(conversation_id)
